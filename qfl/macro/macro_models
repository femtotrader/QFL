import pandas as pd
import numpy as np
import datetime as dt
from pandas_datareader import data as pdata
from qfl.core.data_interfaces import QuandlApi
from sklearn.decomposition import PCA, FactorAnalysis
import matplotlib.pyplot as plt

tickers = ['VT', 'ITOT', 'IWM', 'SPY', 'QQQ',
           'VGK', 'EEM', 'EWJ', 'AAXJ', 'EWY', 'EWZ', 'FXI',
           'HYG', 'USO', 'GLD', 'UUP', 'FXY', 'TLT',
           'XLE', 'XLY', 'XLB', 'XLI', 'XLP', 'XLU', 'XLK', 'XLV', 'XLF']

start_date = dt.datetime(2005, 1, 1)

raw_data = pdata.get_data_yahoo(tickers, start_date)
data = raw_data['Adj Close']

return_window_days = 5
returns = data / data.shift(return_window_days) - 1
returns_clean = returns[np.isfinite(returns).all(axis=1)]

returns_clean_z = (returns_clean - returns_clean.mean(axis=0)) \
                  / returns_clean.std(axis=0)

fit_start_date = dt.datetime(2014, 1, 1)
returns_fit = returns_clean_z[returns_clean_z.index > fit_start_date]
p = PCA(whiten=True)
x = p.fit_transform(returns_fit)
x = pd.DataFrame(index=returns_fit.index, data=x)

# plt.plot(x[[0, 1, 2]].cumsum())

w = pd.DataFrame(columns=returns.columns,
                 data=p.components_)

factor_index = 2
pos = np.arange(len(tickers)) + 0.5
plt.figure(1)
w0 = w.iloc[factor_index].sort_values()
plt.barh(pos, w0, align='center')
labels = tuple(w0.index)
plt.yticks(pos, labels)





# Silly graphing


###############################################################################

import numpy as np
import matplotlib.pyplot as plt
try:
    from matplotlib.finance import quotes_historical_yahoo
except ImportError:
    from matplotlib.finance import quotes_historical_yahoo_ochl as quotes_historical_yahoo
from matplotlib.collections import LineCollection

from sklearn import cluster, covariance, manifold

###############################################################################
# Retrieve the data from Internet
d1 = dt.datetime(2010, 1, 1)
d2 = dt.datetime.today()

symbols = np.array(tickers).T
variation = returns_clean.values.T

###############################################################################
# Learn a graphical structure from the correlations
edge_model = covariance.GraphLassoCV()

# standardize the time series: using correlations rather than covariance
# is more efficient for structure recovery
X = variation.copy().T
X /= X.std(axis=0)
edge_model.fit(X)

###############################################################################
# Cluster using affinity propagation

_, labels = cluster.affinity_propagation(edge_model.covariance_)
n_labels = labels.max()

for i in range(n_labels + 1):
    print('Cluster %i: %s' % ((i + 1), ', '.join(symbols[labels == i])))

###############################################################################
# Find a low-dimension embedding for visualization: find the best position of
# the nodes (the stocks) on a 2D plane

# node_position_model = manifold.LocallyLinearEmbedding(
#     n_components=3, eigen_solver='dense', n_neighbors=6)

node_position_model = PCA(n_components=3)
embedding = node_position_model.fit_transform(X.T).T
f1 = 0
f2 = 1

###############################################################################
# Visualization
plt.figure(1, facecolor='w', figsize=(10, 8))
plt.clf()
ax = plt.axes([0., 0., 1., 1.])
plt.axis('off')

# Display a graph of the partial correlations
partial_correlations = edge_model.precision_.copy()
d = 1 / np.sqrt(np.diag(partial_correlations))
partial_correlations *= d
partial_correlations *= d[:, np.newaxis]
non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)

# Plot the nodes using the coordinates of our embedding
plt.scatter(embedding[f1],
            embedding[f2],
            s=100 * d ** 2,
            c=labels,
            cmap=plt.cm.spectral)

# Plot the edges
start_idx, end_idx = np.where(non_zero)
segments = [[embedding[[f1, f2], start], embedding[[f1, f2], stop]]
            for start, stop in zip(start_idx, end_idx)]
values = np.abs(partial_correlations[non_zero])
lc = LineCollection(segments,
                    zorder=0,
                    cmap=plt.cm.hot_r,
                    norm=plt.Normalize(0, .7 * values.max()))
lc.set_array(values)
lc.set_linewidths(15 * values)
ax.add_collection(lc)

# Add a label to each node. The challenge here is that we want to
# position the labels to avoid overlap with other labels
label_offset = 0.002

for index, (name, label, (f_1, f_2, f_3)) in enumerate(
        zip(symbols, labels, embedding.T)):

    if f1 == 0:
        x = f_1
    if f1 == 1:
        x = f_2
    if f1 == 2:
        x = f_3

    if f2 == 0:
        y = f_1
    if f2 == 1:
        y = f_2
    if f2 == 2:
        y = f_3

    dx = x - embedding[f1]
    dx[index] = 1
    dy = y - embedding[f2]
    dy[index] = 1
    this_dx = dx[np.argmin(np.abs(dy))]
    this_dy = dy[np.argmin(np.abs(dx))]
    if this_dx > 0:
        horizontalalignment = 'left'
        x += label_offset
    else:
        horizontalalignment = 'right'
        x -= label_offset
    if this_dy > 0:
        verticalalignment = 'bottom'
        y += label_offset
    else:
        verticalalignment = 'top'
        y -= label_offset
    plt.text(x, y, name, size=10,
             horizontalalignment=horizontalalignment,
             verticalalignment=verticalalignment,
             bbox=dict(facecolor='w',
                       edgecolor=plt.cm.spectral(label / float(n_labels)),
                       alpha=.6))

plt.xlim(embedding[f1].min() - .15 * embedding[f1].ptp(),
         embedding[f1].max() + .10 * embedding[f1].ptp(),)
plt.ylim(embedding[f2].min() - .03 * embedding[f2].ptp(),
         embedding[f2].max() + .03 * embedding[f2].ptp())

plt.show()